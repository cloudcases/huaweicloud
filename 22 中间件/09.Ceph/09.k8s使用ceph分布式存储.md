# k8s使用ceph分布式存储

[![img](https://upload.jianshu.io/users/upload_avatars/23298577/b95c4d16-30ef-4f9f-a7cb-78aa5fd496e9?imageMogr2/auto-orient/strip|imageView2/1/w/96/h/96/format/webp)](https://www.jianshu.com/u/16d014957352)

[与诗小睡](https://www.jianshu.com/u/16d014957352)关注

2020.06.21 20:34:39字数 485阅读 242

# ceph简单介绍

- eph是一个可靠地，自动重均衡、自动恢复的分布式存储系统，根据使用场景可以划分为对象存储、块存储和文件系统服务

# ceph组件:

- ## ceph OSDs

存储数据、复制数据、平衡数据、恢复数据等，与其他osd间进行心跳检查等，并将变化上报给ceph Monitor，一般情况一块磁盘对应一个OSD，由OSD管理磁盘，或者一个分区也可以成为一个OSD
一般写数据到ceph集群时，都会先将数据写到Journal盘，然后每隔一段时间将Journal盘的数据刷新到文件系统中，一般为了读写延迟小，会采用SSD硬盘，分配10G，ceph引用Journal盘可以让ceph OSD功能很快做小的写操作；一个随机写入在一个连续类型的Journal，然后刷新到文件系统，这样可以给文件系统足够时间来合并写入磁盘。可以很有效的缓冲突发负载

- ## ceph Monitor

  负载监视ceph集群，维护ceph集群的健康状态，同时维护ceph集群中各种map图，如OSD Map、Monitor Map、PG Map和CRUSH Map，统称为cluster map，cluster map是RADOS的关键数据结构，管理集群中的所有成员、关系、属性等信息以及数据的分发。比如：当用户需要存储数据到ceph集群时，OSD需要先通过Monitor获取最新的map图，然后根据map图和object id等计算出数据最终存储的位置

- ## ceph MDS

全称ceph metadata server，主要保存文件系统服务的元数据，但对象存储和快存储是不需要使用这个服务的

# ceph常用的命令



```bash
#查看已经创建的磁盘
 rbd ls -l 
#查看ceph集群 
 ceph osd tree
#查看ceph授权信息
ceph auth get client.admin
#清除磁盘上的逻辑卷
 /usr/sbin/ceph-volume lvm zap --destroy /dev/vdc
#手动创建一个rbd磁盘
rbd create --image-feature layering [rbd-name] -s 10240
#移除monitor节点
 ceph-deploy mon destroy node4
#详细列出集群每块磁盘的使用情况
    ceph osd df
#检查 MDS 状态:
ceph mds stat
```

https://www.jianshu.com/p/9dd4e8336659