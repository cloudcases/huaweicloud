# kafka安装配置

[1004_d014](https://www.jianshu.com/u/691c9715a04a)

2020.09.10 23:29:56字数 2,066阅读 395

## Kafka介绍

官网   [http://kafka.apache.org](https://links.jianshu.com/go?to=http%3A%2F%2Fkafka.apache.org)

官方文档  [https://kafka.apachecn.org/documentation.html#api](https://links.jianshu.com/go?to=https%3A%2F%2Fkafka.apachecn.org%2Fdocumentation.html%23api)

客户端下载地址 [https://cwiki.apache.org/confluence/display/KAFKA/Clients](https://links.jianshu.com/go?to=https%3A%2F%2Fcwiki.apache.org%2Fconfluence%2Fdisplay%2FKAFKA%2FClients)

kafka是一个多分区、多副本并且基于zookeeper协调的分布式消息系统。目前Kafka已经定位为一个分布式流处理平台，它以高吞吐、可持续化、可水平扩展、支持流处理等多种特性而被广泛应用。

### 1.kafka特性

**特性**

1. 高吞吐量、低延迟：每秒可以处理几十万条消息，延迟最低只有几毫秒，每个主题可以分多个分区，消费组对分区进行消费操作。
2. 可扩展：kafka集群支持热扩展。
3. 持续性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失。
4. 容错性：允许集群中节点失败（若副本数量为n，则允许n-1个节点失败）。
5. 高并发：支持数个客户端同时读写。

**使用场景**

1. 日志收集：通过收集各种服务log，通过kafka以统一接口服务方式开放给各种consumer，如Hadoop、Hbase、Solr等。
2. 消息系统：解耦和生产者和消费者、缓存消息等。
3. 用户活动跟踪：用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到Hadoop、数据仓库中做离线分析和挖掘。
4. 运营指标：用来记录运营监控数据。包括收集各个分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
5. 流处理：比如spark streaming和storm。

### 2. 概念详解

- Kafka作为一个集群，运行在一台或者多台服务器上.
- Kafka 通过 *topic* 对存储的流数据进行分类。
- 每条记录中包含一个key，一个value和一个timestamp（时间戳）。

Kafka有四个核心的API:

- The [Producer API](https://links.jianshu.com/go?to=https%3A%2F%2Fkafka.apachecn.org%2Fdocumentation.html%23producerapi) 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。
- The [Consumer API](https://links.jianshu.com/go?to=https%3A%2F%2Fkafka.apachecn.org%2Fdocumentation.html%23consumerapi) 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。
- The [Streams API](https://links.jianshu.com/go?to=https%3A%2F%2Fkafka.apachecn.org%2Fdocumentation%2Fstreams) 允许一个应用程序作为一个*流处理器*，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。
- The [Connector API](https://links.jianshu.com/go?to=https%3A%2F%2Fkafka.apachecn.org%2Fdocumentation.html%23connect) 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。

**Topics和日志**
Topic 就是数据主题，是数据记录发布的地方,可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。
每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，我们称之为offset，offset用来唯一的标识分区中每一条记录。
Kafka 集群保留所有发布的记录—无论他们是否已被消费—并通过一个可配置的参数——保留期限来控制. 举个例子， 如果保留策略设置为2天，一条记录发布后两天内，可以随时被消费，两天过后这条记录会被抛弃并释放磁盘空间。Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题.

**分布式**
日志的分区partition （分布）在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性.

每个分区都有一台 server 作为 “leader”，零台或者多台server作为 follwers 。leader server 处理一切对 partition （分区）的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers 中的一台服务器会自动成为新的 leader。每台 server 都会成为某些分区的 leader 和某些分区的 follower，因此集群的负载是平衡的。

**消费者**
每个消费者组都会有一个独一无二的消费者组id来标记自己。每一个消费者group可能有一个或者多个消费者，对于当前消费组来说，topic中每条数据只要被消费组内任何一个消费者消费一次，那么这条数据就可以认定被当前消费组消费成功。

一个kafka主题会有多个分区，分配partition需要保证每个分区都有消费者消费，topic的每个分区只能分配给某个消费组下的一个消费者，这样的话也能保证每个partition的顺序消费，如果分区数目比较多那么一个消费者会被分配到多个分区，如果分区数目比较少，但是消费者数目比较多，某些消费者就会处于空闲状态

消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。

**broker**
Kafka 集群包含一个或多个服务器，服务器节点称为broker。

**partition**
topic中的数据分割为一个或多个partition。

**Follower与Leader**
kafka每个分区都有一个单独的leader，0个或多个follower。
Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。

## kafka单机安装

### 1.Java环境

```shell
tar axf jdk-14.0.2_linux-x64_bin.tar.gz  -C /usr/local/
ln -sn /usr/local/jdk-14.0.2  /usr/local/java
cd /usr/local/java/
bin/jlink --module-path jmods --add-modules java.desktop --output jre

# 配置环境变量    EOF加\防变量解析
cat >>/etc/profile <<\EOF

# java
export JAVA_HOME=/usr/local/java
export JRE_HOME=/usr/local/java/jre
export CLASSPATH=.:$JAVA_HOME/lib/:$JRE_HOME/lib
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
EOF
```

### 2.zookeeper安装

**下载**

[https://www.apache.org/dyn/closer.lua/zookeeper/](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.apache.org%2Fdyn%2Fcloser.lua%2Fzookeeper%2F)

```sell
tar -axf apache-zookeeper-3.6.1-bin.tar.gz -C /opt/
ln -sn  /opt/apache-zookeeper-3.6.1-bin /opt/zookeeper
cd /opt/zookeeper/conf/
cp zoo_sample.cfg zoo.cfg
mkdir -p /data/zookeeper
```

**配置文件**

```shell
# 服务器心跳时间，毫秒为单位
tickTime=2000
# 集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数
initLimit=5
# 集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数
syncLimit=2
# 数据目录
dataDir=/data/zookeeper
# 对外服务端口
clientPort=2181
```

**启动**

```shell
/opt/zookeeper/bin/zkServer.sh start
ps axu |grep zookeeper
jps -l
```

### 3.kafka安装

**下载**  [https://www.apache.org/dyn/closer.cgi?path=/kafka/2.6.0/kafka_2.13-2.6.0.tgz](https://links.jianshu.com/go?to=https%3A%2F%2Fwww.apache.org%2Fdyn%2Fcloser.cgi%3Fpath%3D%2Fkafka%2F2.6.0%2Fkafka_2.13-2.6.0.tgz)

```shell
tar axf kafka_2.13-2.6.0.tgz -C /opt
ln -sn /opt/kafka_2.13-2.6.0/  /opt/kafka
mkdir -p /data/kafka
```

**配置文件**

```shell
broker.id=0             # 必须为每个代理设置一个唯一的整数
num.network.threads=8   # 服务器用于从网络接收请求并向网络发送响应的线程数 
num.io.threads=16        # 服务器用于处理请求的线程数，可能包括磁盘I / O.
socket.send.buffer.bytes=102400      # 套接字服务器使用的发送缓冲区
socket.receive.buffer.bytes=102400   # 套接字服务器使用的接收缓冲区
socket.request.max.bytes=104857600   # 套接字服务器将接受的请求的最大大小（防止OOM）
log.dirs=/data/kafka/log
num.partitions=1                     # 建议broker少的话，默认就几个broker 就设置成几个分区
num.recovery.threads.per.data.dir=1  # 在启动时用于日志恢复和在关闭时刷新的每个数据目录的线程数。
                                       对于数据目录位于RAID阵列中的安装，建议增加此值。
                                       offsets.topic.replication.factor=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1 
//以上3个推荐＃组元数据内部主题“__consumer_offsets”和“__transaction_state”的复制因子对于除开发测试之外的任何其他内容，建议使用大于1的值以确保可用性，例如3。
#log.flush.interval.messages=10000      # 强制刷新数据到磁盘之前要接受的消息数 
#log.flush.interval.ms=1000             # 强制刷新之前消息可以在日志中停留的最长时间 

log.retention.hours=24                  # 默认消息的最大持久化时间，168小时，7天 
#log.retention.bytes = 1073741824       # 日志的基于大小的保留策略
log.segment.bytes=1073741824            # 这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
log.retention.check.interval.ms=300000  # 每隔300000毫秒去检查上面配置的log失效时间 

zookeeper.connect=10.0.0.2:2181,10.0.0.3:2181,10.0.0.4:2181 # 设置zookeeper的连接端口
zookeeper.connection.timeout.ms=60000   # 设置zookeeper的连接超时时间 
group.initial.rebalance.delay.ms=3      # 指定GroupCoordinator将延迟初始消费者重新平衡的时间毫秒
```

**必要配置**

```shell
broker.id=0 
log.dirs=/data/kafka/log
advertised.listeners=PLAINTEXT://10.0.0.2:9092    # 让注册到ZK上是IP，而不是主机名，10版后本
zookeeper.connect=10.0.0.2:2181
```

**启动**

```shell
nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &
jps -l
```

### 4.kafka测试消息生产与消费

**创建一个主题**

```shell
cd /opt/kafka
bin/kafka-topics.sh \
--zookeeper localhost:2181 \
--create  \
--topic     test1  \
--partitions 2 \
--replication-factor 1  

bin/kafka-topics.sh  --zookeeper localhost:2181  --list  # 展示主题
bin/kafka-topics.sh  --zookeeper localhost:2181  --describe  --topic  test1  # 查看主题详情
```

--topic 指定所创建主题名称
--partitions 指定分区个数
--replication-factor 指定分区副本因子

**启动消费端接受消息，生产端接受消息**

```php
bin/kafka-console-consumer.sh --bootstrap-server 10.0.0.2:9092 --topic test1 

bin/kafka-console-producer.sh --broker-list 10.0.0.2:9092 --topic test1   
                # 输入消息，类似nc
```



## zookeeper-kafka集群

### zookeep概述

1. zookeeper是开源分布式的，为分布式应用提供协调服务的apache项目
2. 一个领导者leader，多个跟随着follower组成的集群
3. 全局一致性：每个server保持一份相同的数据副本，client无论连接哪个server，数据都是一致的
4. 更新请求顺序进行，来自同一client的更新情求按其发送顺序依次进行
5. 数据原子性，一次数据跟新要么所有server全部成功，要么全部失败
6. 实时性，在一定时间范围内，client能读到最新数据
7. 在 ZooKeeper 中，“节点"分为两类，机器节点，第二类则是指数据模型中的数据单元，我们称之为数据节点ZNode

### zookeeper集群

| server     | ip       |
| ---------- | -------- |
| zk-server1 | 10.0.0.2 |
| zk-server2 | 10.0.0.3 |
| zk-server3 | 10.0.0.4 |

**修改配置文件**

```ruby
cat  >>/opt/zookeeper/conf/zoo.cfg<<\EOF

server.1=10.0.0.2:2888:3888
server.2=10.0.0.3:2888:3888
server.3=10.0.0.4:2888:3888
EOF
```

**配置myid **

```bash
echo 1 > /data/zookeeper/myid          # 在zk-server1配置
echo 2 > /data/zookeeper/myid          # 在zk-server2配置
echo 3 > /data/zookeeper/myid          # 在zk-server3配置
```

**启动集群**

```bash
/opt/zookeeper/bin/zkServer.sh start
/opt/zookeeper/bin/zkServer.sh status           # 查看当前状态Mode: leader   Mode: follower
```

### kafak集群

| server     | ip       |
| ---------- | -------- |
| ka-server1 | 10.0.0.2 |
| ka-server2 | 10.0.0.3 |
| ka-server3 | 10.0.0.4 |

```shell
broker.id=0                       # ka-server1配0  ka-server2配1  ka-server1配3           
log.dirs=/data/kafka/log
advertised.listeners=PLAINTEXT://10.0.0.2:9092   # 根据节点配置   
zookeeper.connect=10.0.0.2:2181,10.0.0.3:2181,10.0.0.4:2181
```

**启动**

```undefined
nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &
jps -l
```



https://www.jianshu.com/p/779023bf5f67